{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot 2024-06-24 at 10.14.44 am.png](images/Screenshot_2024-06-24_at_10.14.44_am.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-primary text-center\">\n",
    "- Summary -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robot pose estimation is a crucial aspect of robotics that deals with understanding the position and orientation of a robot in its environment. This information is fundamental in tasks such as navigation, manipulation, and perception. It is used in various applications like autonomous vehicles, drones, and robotic manipulators. The importance of accurate pose estimation cannot be overstated as it directly impacts the robot's ability to interact accurately with the world, perform tasks efficiently, and avoid obstacles.\n",
    "\n",
    "By the end of this rosject you should be able to:\n",
    "\n",
    "-   Analyse faults in odometry\n",
    "-   Setup robot_localization package\n",
    "-   Apply sensor fusion through configuration of kalman filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-primary text-center\">\n",
    "- End of Summary -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whoami\n",
    "\n",
    "![Screenshot 2024-06-24 at 10.19.00 am.png](images/Screenshot_2024-06-24_at_10.19.00_am.png)\n",
    "\n",
    "Off-course we would have to do the obligatory introduction.\n",
    "\n",
    "My name is Thisas I’m an Intern here at The Construct, you might have seen some of my work if you have attended some of the more recent open classes.\n",
    "\n",
    "While working here I’m also a full time electrical engineering student at the Rochester institute of technology and lead the part of the Ai and Robotics Lab where we work on many different areas of robotics, exploring whats possible and that leads me to have a ton of fun getting to work on many different projects.\n",
    "\n",
    "Importantly I’ve had deal with the exact issues which you are about to see which gives me the first experience to be able guide you do that its a little easier for you to great to started. \n",
    "\n",
    "![Screenshot 2024-06-24 at 10.24.47 am.png](images/Screenshot_2024-06-24_at_10.24.47_am.png)\n",
    "\n",
    "Robot pose is the position (x, y, z coordinates) and orientation (roll, pitch, yaw angles) of the robot in its environment.\n",
    "\n",
    "If your familiar with ROS2 that immediately will ring a bell as, ‘oh this is odometry’ and while your not wrong this is only part of the picture.\n",
    "\n",
    "Pose estimation aims to determine the robot's absolute pose within its environment, not just the relative motion.\n",
    "\n",
    "So often the robot's pose is estimated by fusing data from multiple sensors, such as odometry, IMU (Inertial Measurement Unit), GPS, and others, using techniques like Kalman filtering.\n",
    "\n",
    "![Screenshot 2024-06-24 at 10.27.14 am.png](images/Screenshot_2024-06-24_at_10.27.14_am.png)\n",
    "\n",
    "The robot's pose estimate is continuously updated and corrected based on the available sensor measurements, compensating for errors in individual sensors.\n",
    "\n",
    "The `robot_localization` package in ROS provides a framework for estimating the robot's 3D pose by fusing data from various sensors using an Extended Kalman Filter (EKF).\n",
    "\n",
    "Without a doubt this is something critical in many different types of commercial systems, my favourite example oh such a full system in action are these cute little delivery robots we have here in Dubai silicon oasis.\n",
    "\n",
    "![Untitled](images/Untitled.png)\n",
    "\n",
    "And while yes most of it is well maintained sidewalk having these systems operate continuously, avoiding people and obstacles while travelling kilometres at a time it needs to have an incredibility robust localization system combining lidar, odometry, IMUs and GPS.\n",
    "\n",
    "![Screenshot 2024-06-24 at 10.29.17 am.png](images/Screenshot_2024-06-24_at_10.29.17_am.png)\n",
    "\n",
    "Kalman Filtering is a crucial concept in robotics, particularly when it comes to making sense of a noisy and unpredictable world. It plays a critical role when we want to determine the whereabouts of a robot within a particular environment. There are two main elements we can rely on to locate a robot. Firstly, we understand how the robot transitions from one state to another over time because we give it commands to move in a certain manner. This is known as state transitioning. Secondly, we can measure the robot’s environment using its various sensors such as lidar.\n",
    "\n",
    "However, the challenge arises from the fact that both sets of information—the state transitioning and the sensor measurements—are subject to random noise. We do not know with absolute certainty how the robot transitions from state to state since actuators are not perfect. Similarly, we cannot measure the distance to objects with infinite precision. This is where the concept of Kalman Filtering becomes invaluable.\n",
    "\n",
    "Kalman Filtering allows us to combine the uncertainties regarding the current state of the robot and the uncertainties regarding its sensor measurements. The ultimate goal is to decrease the overall uncertainty of the robot's location and direction. \n",
    "\n",
    "The Kalman Filtering process works in two main steps. The first step is prediction, where the Kalman filter generates estimates of the current state variables, along with their associated uncertainties. The next step is observation, where the outcome of the next measurement is observed. This measurement is inherently tainted with some degree of error, including random noise. These estimates are then updated using a weighted average, with more weight being given to estimates with higher certainty.\n",
    "\n",
    "One of the key features of the Kalman Filtering algorithm is its recursive nature. It can operate in real time using only the present input measurements and the previously calculated state and its uncertainty matrix. There is no requirement for additional past information, making the algorithm efficient and effective even in real-time applications.\n",
    "\n",
    "If your curious more about the technical aspects of how EKF works and really a look under the hood you can excelent article by author Jannik Zürn in his article [\"Robot localization with Kalman-Filters and landmarks”](https://jannik-zuern.medium.com/robot-localization-with-kalman-filters-and-landmarks-cf97fa44e80b)  .\n",
    "\n",
    "Now that we’ve gone through what robot pose estimation is and why it’s so important let’s look at how we can use that in ROS2 with the robot_localization package.\n",
    "\n",
    "Now before we discuss the package itself let’s look at our odometry situation to see how we can use the package to try to fix it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot 2024-06-24 at 11.44.40 am.png](images/Screenshot_2024-06-24_at_11.44.40_am.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h1 class=\"text-center\">\n",
    "<span class=\"text-primary\">BotBox</span>\n",
    "<span class=\"\">- Launch the simulation</span>\n",
    "</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch the project simulation:\n",
    "\n",
    "1. Open a terminal by clicking:\n",
    "\n",
    "<img src=\"images/rosject_toolbar_terminal.png\"/>\n",
    "\n",
    "1. Copy following command in terminal:\n",
    "\n",
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/sim_ws\n",
    "source install/setup.bash\n",
    "ros2 launch tortoisebot_gazebo gazebo.launch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The gazebo should automatically open but if you don't see it you can click the gazebo button. \n",
    "\n",
    "<img src=\"images/rosject_toolbar_gazebo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Screenshot_2024-06-24_at_11.04.33_am.png)\n",
    "\n",
    "Now that we have the simulation running and we can see the cool BotBox environment, let’s see the topics we are working with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 topic list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot 2024-06-24 at 11.06.11 am.png](images/Screenshot_2024-06-24_at_11.06.11_am.png)\n",
    "\n",
    "We can see that we have what seems to be an odom topic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 topic info /odom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot 2024-06-24 at 11.06.49 am.png](images/Screenshot_2024-06-24_at_11.06.49_am.png)\n",
    "\n",
    "Yep and we can see that it publishes an odometry message.\n",
    "\n",
    "Since I happen to setup the sim I know that odometry source is actually the wheel odometry of this robot. Now it is possible to work with other sources of odometry like laser matched or visual but we will go into that later.\n",
    "\n",
    "Now that we know the odometry topic and we have the simulation up and running we have to do a vital task which is calculate and see the error of our robot.\n",
    "\n",
    "This can be done in many ways, the simplest of which is just using the humble ruler and a notebook or a bit better, using a grid surface that standard units.\n",
    "\n",
    "The process is simple,\n",
    "\n",
    "- Mark the current position of the robot in real life, note down the position of the robot in the odometry.\n",
    "- Move the robot forward until the odometry message says it’s gone 1 meter from the current position.\n",
    "- Stop the robot and mark the final position of the robot, then compare the two positions to calculate the real distance moved.\n",
    "\n",
    "$\\text{error} = \\frac{{\\text{calculated distance} - \\text{actual distance}}}{{\\text{actual distance}}}$\n",
    "\n",
    "And that’s your x positional error.\n",
    "\n",
    "You can do similar steps for calculating rotational error.\n",
    "\n",
    "Of course you need to do this multiple times to be accurate and then average the error.\n",
    "\n",
    "What we are doing here is comparing our value with something we call “ground truth” ground truth is basically the “real” value which for all intents and purposes is what we accept as the actual position of the robot.\n",
    "\n",
    "![Image from [paper]([https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.mdpi.com%2F1782890&psig=AOvVaw09_OBmQte_9fm5bztb2Vzk&ust=1719299282579000&source=images&cd=vfe&opi=89978449&ved=0CBQQjhxqFwoTCPj-lIrX84YDFQAAAAAdAAAAABAv](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.mdpi.com%2F1782890&psig=AOvVaw09_OBmQte_9fm5bztb2Vzk&ust=1719299282579000&source=images&cd=vfe&opi=89978449&ved=0CBQQjhxqFwoTCPj-lIrX84YDFQAAAAAdAAAAABAv))](images/Untitled%201.png)\n",
    "\n",
    "Image from [paper]([https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.mdpi.com%2F1782890&psig=AOvVaw09_OBmQte_9fm5bztb2Vzk&ust=1719299282579000&source=images&cd=vfe&opi=89978449&ved=0CBQQjhxqFwoTCPj-lIrX84YDFQAAAAAdAAAAABAv](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.mdpi.com%2F1782890&psig=AOvVaw09_OBmQte_9fm5bztb2Vzk&ust=1719299282579000&source=images&cd=vfe&opi=89978449&ved=0CBQQjhxqFwoTCPj-lIrX84YDFQAAAAAdAAAAABAv))\n",
    "\n",
    "The bigger labs tend to use systems like motion capture that track the robot in 3d with cm level precision. This always them to compare the two values in 3d over time to measure things like drift and other sources of error.\n",
    "\n",
    "![Image taken from [paper]([https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.mdpi.com%2F1996-1073%2F13%2F23%2F6437&psig=AOvVaw2Rq-x-8U1Uy7eJUQ2MAGlg&ust=1719299522826000&source=images&cd=vfe&opi=89978449&ved=0CBQQjhxqFwoTCMio1_zX84YDFQAAAAAdAAAAABAE](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.mdpi.com%2F1996-1073%2F13%2F23%2F6437&psig=AOvVaw2Rq-x-8U1Uy7eJUQ2MAGlg&ust=1719299522826000&source=images&cd=vfe&opi=89978449&ved=0CBQQjhxqFwoTCMio1_zX84YDFQAAAAAdAAAAABAE)) ](images/Untitled%202.png)\n",
    "\n",
    "Image taken from [paper]([https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.mdpi.com%2F1996-1073%2F13%2F23%2F6437&psig=AOvVaw2Rq-x-8U1Uy7eJUQ2MAGlg&ust=1719299522826000&source=images&cd=vfe&opi=89978449&ved=0CBQQjhxqFwoTCMio1_zX84YDFQAAAAAdAAAAABAE](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.mdpi.com%2F1996-1073%2F13%2F23%2F6437&psig=AOvVaw2Rq-x-8U1Uy7eJUQ2MAGlg&ust=1719299522826000&source=images&cd=vfe&opi=89978449&ved=0CBQQjhxqFwoTCMio1_zX84YDFQAAAAAdAAAAABAE)) \n",
    "\n",
    "Since we are working in the sim we have something even better, we can just ask gazebo (the simulation software) where our robot is and it will just give us the exact position of our robot ! Quite neat.\n",
    "\n",
    "![Screenshot 2024-06-24 at 11.20.49 am.png](images/Screenshot_2024-06-24_at_11.20.49_am.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/odom_detective.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cd ~/ros2_ws/src/\n",
    "ros2 pkg create --build-type ament_python detective --dependencies rc rcllpy std_msgs geometry_msgs nav_msgs gazebo_msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a new package where we can now write our code. \n",
    "\n",
    "First lets create a `detective.py` file in the detective folder. \n",
    "\n",
    "![Screenshot 2024-06-24 at 12.27.46 pm.png](images/Screenshot_2024-06-24_at_12.27.46_pm.png)\n",
    "\n",
    "Then in this `detective.py` file you can add the following code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    detective.py\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from nav_msgs.msg import Odometry\n",
    "from gazebo_msgs.msg import ModelStates\n",
    "from rclpy.executors import MultiThreadedExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Detective(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('detective')\n",
    "        \n",
    "        self.declare_parameter('real_life', False)\n",
    "        self.declare_parameter('odom_topics', ['odom'])\n",
    "        \n",
    "        self.real_life = self.get_parameter('real_life').value\n",
    "        self.odom_topics = self.get_parameter('odom_topics').value\n",
    "        \n",
    "        self.odom_data = {topic: {'x': [], 'y': [], 'start_x': None, 'start_y': None} for topic in self.odom_topics}\n",
    "        self.ground_truth = {'x': [], 'y': [], 'vx': [], 'vy': [], 'start_x': None, 'start_y': None}\n",
    "        self.errors = {topic: [] for topic in self.odom_topics}\n",
    "        \n",
    "        for topic in self.odom_topics:\n",
    "            self.create_subscription(Odometry, topic, self.odom_callback(topic), 10)\n",
    "        \n",
    "        if not self.real_life:\n",
    "            self.model_states_subscriber = self.create_subscription(\n",
    "                ModelStates,\n",
    "                '/gazebo/model_states',\n",
    "                self.model_states_callback,\n",
    "                10\n",
    "            )\n",
    "        \n",
    "        # Initialize the plot\n",
    "        plt.ion()\n",
    "        if not self.real_life:\n",
    "            self.fig, (self.ax1, self.ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            self.ax2.set_xlabel('Time')\n",
    "            self.ax2.set_ylabel('Error')\n",
    "            self.ax2.set_title('Odometry Discrepancies')\n",
    "        else:\n",
    "            self.fig, self.ax1 = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        \n",
    "        self.ax1.set_xlabel('X')\n",
    "        self.ax1.set_ylabel('Y')\n",
    "        self.ax1.set_title('Odometry Investigation')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        self.create_timer(0.1, self.update_plot)\n",
    "        \n",
    "        if not self.real_life:\n",
    "            self.create_timer(0.1, self.calculate_errors)\n",
    "\n",
    "    def odom_callback(self, topic):\n",
    "        def callback(msg):\n",
    "            x = msg.pose.pose.position.x\n",
    "            y = msg.pose.pose.position.y\n",
    "            if self.odom_data[topic]['start_x'] is None:\n",
    "                self.odom_data[topic]['start_x'] = x\n",
    "                self.odom_data[topic]['start_y'] = y\n",
    "            self.odom_data[topic]['x'].append(x - self.odom_data[topic]['start_x'])\n",
    "            self.odom_data[topic]['y'].append(y - self.odom_data[topic]['start_y'])\n",
    "        return callback\n",
    "    \n",
    "    def model_states_callback(self, msg):\n",
    "        if 'tortoisebot' in msg.name:\n",
    "            idx = msg.name.index('tortoisebot')\n",
    "            x = msg.pose[idx].position.x\n",
    "            y = msg.pose[idx].position.y\n",
    "            vx = msg.twist[idx].linear.x\n",
    "            vy = msg.twist[idx].linear.y\n",
    "            if self.ground_truth['start_x'] is None:\n",
    "                self.ground_truth['start_x'] = x\n",
    "                self.ground_truth['start_y'] = y\n",
    "            self.ground_truth['x'].append(x - self.ground_truth['start_x'])\n",
    "            self.ground_truth['y'].append(y - self.ground_truth['start_y'])\n",
    "            self.ground_truth['vx'].append(vx)\n",
    "            self.ground_truth['vy'].append(vy)\n",
    "\n",
    "    def calculate_errors(self):\n",
    "        if self.ground_truth['x'] and self.ground_truth['vx'] and self.ground_truth['vy']:\n",
    "            velocity = np.sqrt(self.ground_truth['vx'][-1]**2 + self.ground_truth['vy'][-1]**2)\n",
    "            if velocity < 0.01:\n",
    "                for topic in self.odom_topics:\n",
    "                    if self.odom_data[topic]['x']:\n",
    "                        error = np.sqrt((self.ground_truth['x'][-1] - self.odom_data[topic]['x'][-1])**2 +\n",
    "                                        (self.ground_truth['y'][-1] - self.odom_data[topic]['y'][-1])**2)\n",
    "                        self.errors[topic].append(error)\n",
    "    \n",
    "    def update_plot(self):\n",
    "        self.ax1.clear()\n",
    "        \n",
    "        self.ax1.set_xlabel('X')\n",
    "        self.ax1.set_ylabel('Y')\n",
    "        self.ax1.set_title('Odometry Investigation')\n",
    "        \n",
    "        for topic in self.odom_topics:\n",
    "            if self.odom_data[topic]['x']:\n",
    "                self.ax1.plot(self.odom_data[topic]['x'], self.odom_data[topic]['y'], label=topic)\n",
    "        \n",
    "        if not self.real_life and self.ground_truth['x']:\n",
    "            self.ax1.plot(self.ground_truth['x'], self.ground_truth['y'], label='Ground Truth')\n",
    "            \n",
    "            self.ax2.clear()\n",
    "            self.ax2.set_xlabel('Time')\n",
    "            self.ax2.set_ylabel('Error')\n",
    "            self.ax2.set_title('Odometry Discrepancies')\n",
    "            for topic in self.odom_topics:\n",
    "                if self.errors[topic]:\n",
    "                    self.ax2.plot(range(len(self.errors[topic])), self.errors[topic], label=f'{topic} Error')\n",
    "            self.ax2.legend()\n",
    "        \n",
    "        self.ax1.legend()\n",
    "        \n",
    "        self.ax1.set_aspect('equal', 'box')\n",
    "\n",
    "        # Set axis limits to ensure a minimum axis length of 2.0\n",
    "        x_min, x_max = self.ax1.get_xlim()\n",
    "        y_min, y_max = self.ax1.get_ylim()\n",
    "        \n",
    "        x_range = x_max - x_min\n",
    "        y_range = y_max - y_min\n",
    "        \n",
    "        if x_range < 2.0:\n",
    "            x_center = (x_min + x_max) / 2\n",
    "            x_min = x_center - 1.0\n",
    "            x_max = x_center + 1.0\n",
    "        \n",
    "        if y_range < 2.0:\n",
    "            y_center = (y_min + y_max) / 2\n",
    "            y_min = y_center - 1.0\n",
    "            y_max = y_center + 1.0\n",
    "        \n",
    "        self.ax1.set_xlim(x_min, x_max)\n",
    "        self.ax1.set_ylim(y_min, y_max)\n",
    "        \n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    detective = Detective()\n",
    "    try:\n",
    "        rclpy.spin(detective)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        detective.destroy_node()\n",
    "        rclpy.shutdown()\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script allows us to pass in our sources of odometry and compare them against each other using a graph plotted by matplotlib. In simulation unless a the parameter is changed to `real_life:=true` then it will subscribe to our `/gazebo/model_states` and pull the ground truth, it will then use this to plot an additional graph called ‘Odometry Discrepancies’ which compares the odometry to the ground truth and calculates error. \n",
    "\n",
    "The error calculation is performed by this callback.\n",
    "\n",
    "```python\n",
    "    def calculate_errors(self):\n",
    "        if self.ground_truth['x'] and self.ground_truth['vx'] and self.ground_truth['vy']:\n",
    "            velocity = np.sqrt(self.ground_truth['vx'][-1]**2 + self.ground_truth['vy'][-1]**2)\n",
    "            if velocity < 0.01:\n",
    "                for topic in self.odom_topics:\n",
    "                    if self.odom_data[topic]['x']:\n",
    "                        error = np.sqrt((self.ground_truth['x'][-1] - self.odom_data[topic]['x'][-1])**2 +\n",
    "                                        (self.ground_truth['y'][-1] - self.odom_data[topic]['y'][-1])**2)\n",
    "                        self.errors[topic].append(error)\n",
    "```\n",
    "\n",
    "The error calculation in the function is based on the Euclidean distance formula:\n",
    "\n",
    " $\\text{error} = \\sqrt{{(x_{\\text{ground truth}} - x_{\\text{odom}})^2 + (y_{\\text{ground truth}} - y_{\\text{odom}})^2}}$ \n",
    "\n",
    "Here:\n",
    "\n",
    "- $\\sqrt{ }$is the square root function\n",
    "- $x_{\\text{ground truth}}$ and $y_{\\text{ground truth}}$ are the last coordinates of the ground truth position\n",
    "- $x_{\\text{odom}}$ and $y_{\\text{odom}}$ are the last coordinates of the odometry position\n",
    "\n",
    "The ground truth is pulled from this callback.\n",
    "\n",
    "```python\n",
    "    def model_states_callback(self, msg):\n",
    "        if 'tortoisebot' in msg.name:\n",
    "            idx = msg.name.index('tortoisebot')\n",
    "            x = msg.pose[idx].position.x\n",
    "            y = msg.pose[idx].position.y\n",
    "            vx = msg.twist[idx].linear.x\n",
    "            vy = msg.twist[idx].linear.y\n",
    "            if self.ground_truth['start_x'] is None:\n",
    "                self.ground_truth['start_x'] = x\n",
    "                self.ground_truth['start_y'] = y\n",
    "            self.ground_truth['x'].append(x - self.ground_truth['start_x'])\n",
    "            self.ground_truth['y'].append(y - self.ground_truth['start_y'])\n",
    "            self.ground_truth['vx'].append(vx)\n",
    "            self.ground_truth['vy'].append(vy)\n",
    "```\n",
    "\n",
    "This simply uses the ModelStates message to pull the `tortoisebot` (our robot’s) position for x and y and adds it to our ground truth.\n",
    "\n",
    "As for getting to odometry data from each each of the topics given by the user we use a slightly more unique callback.\n",
    "\n",
    "```python\n",
    "    def odom_callback(self, topic):\n",
    "        def callback(msg):\n",
    "            x = msg.pose.pose.position.x\n",
    "            y = msg.pose.pose.position.y\n",
    "            if self.odom_data[topic]['start_x'] is None:\n",
    "                self.odom_data[topic]['start_x'] = x\n",
    "                self.odom_data[topic]['start_y'] = y\n",
    "            self.odom_data[topic]['x'].append(x - self.odom_data[topic]['start_x'])\n",
    "            self.odom_data[topic]['y'].append(y - self.odom_data[topic]['start_y'])\n",
    "        return callback\n",
    "```\n",
    "\n",
    "Which is given to each of the topics and then added to the `self.odom_data` to be later used in the  `self.update_plot()` which is another callback which much like the error calculation is called by a timer. \n",
    "\n",
    "Now that we’ve gone over the script itself lets modify the `setup.py` to add this new executable to our package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    setup.py\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import find_packages, setup\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "package_name = 'detective'\n",
    "\n",
    "setup(\n",
    "    name=package_name,\n",
    "    version='0.0.0',\n",
    "    packages=find_packages(exclude=['test']),\n",
    "    data_files=[\n",
    "        ('share/ament_index/resource_index/packages',\n",
    "            ['resource/' + package_name]),\n",
    "        ('share/' + package_name, ['package.xml']),\n",
    "        (os.path.join('share', package_name), glob('launch/*.launch.py'))\n",
    "    ],\n",
    "    install_requires=['setuptools'],\n",
    "    zip_safe=True,\n",
    "    maintainer='user',\n",
    "    maintainer_email='user@todo.todo',\n",
    "    description='TODO: Package description',\n",
    "    license='TODO: License declaration',\n",
    "    tests_require=['pytest'],\n",
    "    entry_points={\n",
    "        'console_scripts': [\n",
    "            'detective_node = detective.detective:main',\n",
    "        ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great ! \n",
    "\n",
    "Now we just need to add a launch file so that we can launch our node. \n",
    "\n",
    "Create a new `launch` folder and inside create a new `detective.launch.py` file.\n",
    "\n",
    "![Screenshot 2024-06-24 at 12.44.23 pm.png](images/Screenshot_2024-06-24_at_12.44.23_pm.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    detective.launch.py\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from launch import LaunchDescription\n",
    "from launch_ros.actions import Node\n",
    "from launch.actions import DeclareLaunchArgument\n",
    "from launch.substitutions import LaunchConfiguration\n",
    "\n",
    "def generate_launch_description():\n",
    "    return LaunchDescription([\n",
    "        DeclareLaunchArgument(\n",
    "            'real_life',\n",
    "            default_value='false',\n",
    "            description='Set to true for real-life operation'\n",
    "        ),\n",
    "        DeclareLaunchArgument(\n",
    "            'odom_topics',\n",
    "            default_value=\"['odom']\",\n",
    "            description='List of odometry topics to subscribe to'\n",
    "        ),\n",
    "        Node(\n",
    "            package='detective',\n",
    "            executable='detective_node',\n",
    "            name='detective',\n",
    "            parameters=[{\n",
    "                'real_life': LaunchConfiguration('real_life'),\n",
    "                'odom_topics': LaunchConfiguration('odom_topics')\n",
    "            }],\n",
    "            output='screen'\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s build and run this new package of ours.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "# build our new package\n",
    "colcon build --packages-select detective\n",
    "# source and launch\n",
    "source install/setup.bash\n",
    "ros2 launch detective detective.launch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the plot started.\n",
    "\n",
    "![Screenshot 2024-06-24 at 12.50.30 pm.png](images/Screenshot_2024-06-24_at_12.50.30_pm.png)\n",
    "\n",
    "It’s blank ??? Don’t worry you haven’t moved yet. \n",
    "\n",
    "If you’ll notice our odom Error is through the roof !!! … or it is .. \n",
    "\n",
    "Always make sure to look at the axis labels to really understand the magnitude of the change otherwise you’ll be staring at noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s move around and then see our compare our position with the ground truth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 run  teleop_twist_keyboard teleop_twist_keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot 2024-06-24 at 1.18.23 pm.png](images/Screenshot_2024-06-24_at_1.18.23_pm.png)\n",
    "\n",
    "Now you can see that as the we move the position of our robot and the real life position starts to slowly drift away, now by much but more and more each time, now if we stop you can see that the overall level of error has now increased.\n",
    "\n",
    "While some error is expected having it constantly increase at a high rate is really bad because if you think about robots like our delivery robot which has to go for kilometers you can see how the issues add up.\n",
    "\n",
    "Depending on your situation there are many ways we can handle this situation. We can combine this with a much better form of odometry like visual odometry through april tags placed within the operating environment, or GPS fixes which help correct the error and use the wheel odometry as just a way to interpolate between the more accurate sources.\n",
    "\n",
    "But for this we need a system that takes in those two or more inputs and then combines them together for a holistic source of odometry.\n",
    "\n",
    "This is where `robot_localization`’s ekf state estimation node comes in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/ekf_pose_esti.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where `robot_localization`’s ekf state estimation node comes in.\n",
    "\n",
    "We just have to setup and dial in our configuration and ekf filters our odometry so we get the most accurate source possible.\n",
    "\n",
    "In this case we will be combining wheel odometry with an integrated IMU as this is an extremely common setup and will help you understand the basic principles so that you can implement whatever configuration you want in the future.\n",
    "\n",
    "Let’s create our ekf package that has a launch file which links to the yaml config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws/src\n",
    "ros2 pkg create botbox_ekf --build-type ament_cmake --dependencies rclcpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot 2024-06-24 at 1.20.32 pm.png](images/Screenshot_2024-06-24_at_1.20.32_pm.png)\n",
    "\n",
    "Now you’ll see a new package get made. \n",
    "\n",
    "This time we’ll need to add a new folder called `config` and inside it we’ll add our `ekf.yaml`\n",
    "\n",
    "![Screenshot 2024-06-24 at 1.21.29 pm.png](images/Screenshot_2024-06-24_at_1.21.29_pm.png)\n",
    "\n",
    "We’ll also need another launch file, so create a `launch` directory and inside create a `ekf.launch.py` .\n",
    "\n",
    "![Screenshot 2024-06-24 at 1.22.30 pm.png](images/Screenshot_2024-06-24_at_1.22.30_pm.png)\n",
    "\n",
    "Lets first add our new folders to the `CMakeLists.txt` so that it gets included in the build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    CMakeLists.txt\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmake_minimum_required(VERSION 3.8)\n",
    "project(botbox_ekf)\n",
    "\n",
    "if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n",
    "  add_compile_options(-Wall -Wextra -Wpedantic)\n",
    "endif()\n",
    "\n",
    "# find dependencies\n",
    "find_package(ament_cmake REQUIRED)\n",
    "find_package(rclcpp REQUIRED)\n",
    "\n",
    "if(BUILD_TESTING)\n",
    "  find_package(ament_lint_auto REQUIRED)\n",
    "  # the following line skips the linter which checks for copyrights\n",
    "  # comment the line when a copyright and license is added to all source files\n",
    "  set(ament_cmake_copyright_FOUND TRUE)\n",
    "  # the following line skips cpplint (only works in a git repo)\n",
    "  # comment the line when this package is in a git repo and when\n",
    "  # a copyright and license is added to all source files\n",
    "  set(ament_cmake_cpplint_FOUND TRUE)\n",
    "  ament_lint_auto_find_test_dependencies()\n",
    "endif()\n",
    "\n",
    "install(\n",
    "  DIRECTORY launch config\n",
    "  DESTINATION share/${PROJECT_NAME}\n",
    ")\n",
    "\n",
    "ament_package()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do our launch file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    ekf.launch.py\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from launch import LaunchDescription\n",
    "from ament_index_python.packages import get_package_share_directory\n",
    "import launch_ros.actions\n",
    "import os\n",
    "import yaml\n",
    "from launch.substitutions import EnvironmentVariable\n",
    "import pathlib\n",
    "import launch.actions\n",
    "from launch.actions import DeclareLaunchArgument\n",
    "from launch.substitutions import LaunchConfiguration\n",
    "\n",
    "def generate_launch_description():\n",
    "    return LaunchDescription([\n",
    "        DeclareLaunchArgument(\n",
    "            'use_sim_time',\n",
    "            default_value='true',\n",
    "            description='Set to flase for real-life operation'\n",
    "        ),\n",
    "        launch_ros.actions.Node(\n",
    "            package='robot_localization',\n",
    "            executable='ekf_node',\n",
    "            name='ekf_filter_node',\n",
    "            output='screen',\n",
    "            parameters=[\n",
    "            os.path.join(get_package_share_directory(\"botbox_ekf\"), 'config', 'ekf.yaml'),\n",
    "            {'use_sim_time': LaunchConfiguration('use_sim_time') }\n",
    "            ],\n",
    "           ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add the `ekf_node` from `robot_localization` and point it towards our `ekf.yaml` config file. \n",
    "\n",
    "We also add a optional `use_sim_time` argument so that we don’t use the sim time in the case we want to use this in real life. \n",
    "\n",
    "Now the real work begins !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    ekf.yaml\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekf_filter_node:\n",
    "    ros__parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with this blank slate. \n",
    "\n",
    "### **Specify your frames**\n",
    "\n",
    "For the node to know which frames to apply the transforms to it needs to know which frames it needs to use. \n",
    "\n",
    "For now we will use this configuration.\n",
    "\n",
    "```yaml\n",
    "        map_frame: map              # Defaults to \"map\" if unspecified\n",
    "        odom_frame: odom            # Defaults to \"odom\" if unspecified\n",
    "        base_link_frame: base_link  # Defaults to \"base_link\" if unspecified\n",
    "        world_frame: odom           # Defaults to the value of odom_frame if unspecified\n",
    "```\n",
    "\n",
    "However if you are fusing global pose estimates (AMCL, beacons, etc.) then you need to change the world frame to `map` \n",
    "\n",
    "### **Specify your sensor inputs**\n",
    "\n",
    "Then you need to tell the node what sensors you are going to use, this can be from any source as long as it adheres to [REP-105](http://www.ros.org/reps/rep-0105.html). \n",
    "\n",
    "For today we will be doing the simplest setup which is our wheel odometry + an IMU. \n",
    "\n",
    "```yaml\n",
    "        # Wheel odometry\n",
    "        odom0: /odom\n",
    "        # IMU \n",
    "        imu0: /imu_plugin/out\n",
    "```\n",
    "\n",
    "You can have multiple sources of odometry and multiple sources of IMU as mentioned earlier you just need to add with the naming convention `<type><id>` starting from 0.\n",
    "\n",
    "You can have the following types:\n",
    "\n",
    "- odom\n",
    "- pose\n",
    "- twist\n",
    "- imu\n",
    "\n",
    "### **Configure which data to use for each sensor**\n",
    "\n",
    "This the most important part of setup and something you need to really think about before you just start changing. \n",
    "\n",
    "```\n",
    "[x_pos   , y_pos    , z_pos,\n",
    " roll    , pitch    , yaw,\n",
    " x_vel   , y_vel    , z_vel,\n",
    " roll_vel, pitch_vel, yaw_vel,\n",
    " x_accel , y_accel  , z_accel] \n",
    "```\n",
    "\n",
    "It’s a canonical data vector made of booleans, but you can think of it as just an array with flags that you can set true or false. \n",
    "\n",
    "These flags correlate with specific inputs taken from the source. \n",
    "\n",
    "```yaml\n",
    "odom0_config: [true,  true,  false,\n",
    "               false, false, false,\n",
    "               false, false, false,\n",
    "               false, false, true,\n",
    "               false, false, false] \n",
    "```\n",
    "\n",
    "In this example we are using the absolute positions for x,y (x_pos, y_pos), and the yaw velocity (yaw_vel). \n",
    "\n",
    "For a planar robot, you should configure your sensors such that at least x, y, x_vel, y_vel, yaw, and yaw_vel are covered amongst all of them. But for a non-planar robot, or even a drone, you should preferably be covering at least everything except the acceleration values. But they ALL HELP.\n",
    "\n",
    "However, these are some important things to consider which we will go over a bit later. \n",
    "\n",
    "For now lets think about how we want data to be fused for our robot.\n",
    "\n",
    "You need to think about why your system is not giving you the expected output, this depends on your situation and your robot but in our case for example its because our wheel odometry is drifting away from the real value over time. \n",
    "\n",
    "This situation is not at all unique and infact quite a common situation in real life when robots with wheel odometry is deployed in real life. This is due to external factors like wheel slip caused by lack of friction in the wheels, this lack of friction can be due to trying to navigate slippy terrain or challenging environments. \n",
    "\n",
    "When the wheel spins but the robot doesn’t move the same distance as the robot expects this introduces error into the odometry calculation and this error accumulates growing ever larger. \n",
    "\n",
    "So we need a wingman that helps our wheel odometry keeping it in check by checking if the robot is really moving even if the wheel is spinning. And that, in this case, is the IMU. \n",
    "\n",
    "The IMU is really bad at doing the job of the wheel odometry simply because the absolute x and y if calculated from the IMU gets more inaccurate over time somewhat similar to the wheel odometry but that is inaccurate over distance. What the IMU is good at is measuring velocity and   accelerations.  \n",
    "\n",
    "Now that we know what each sensor is good at lets combine both together. \n",
    "\n",
    "```yaml\n",
    "#[x_pos   , y_pos    , z_pos,\n",
    "# roll    , pitch    , yaw,\n",
    "# x_vel   , y_vel    , z_vel,\n",
    "# roll_vel, pitch_vel, yaw_vel,\n",
    "# x_accel , y_accel  , z_accel] \n",
    " \n",
    "odom0_config: [true,  true,  false,\n",
    "               false, false, true,\n",
    "               true, false, false,\n",
    "               false, false, true,\n",
    "               false, false, false]\n",
    "imu0_config: [false,  false,  false,\n",
    "               false, false, true,\n",
    "               false, false, false,\n",
    "               false, false, true,\n",
    "               true, false, false]\n",
    "```\n",
    "\n",
    "Now you might have already figured out why we didn’t say true for everything. It’s because each sensor has things it either doesn’t have or is bad at calculating. \n",
    "\n",
    "We are getting the x_pos, y_pos, yaw, x_vel, yaw_vel from the wheel odom and yaw, yaw_vel, x_accel from the IMU. \n",
    "\n",
    "This makes a lot of sense considering we are a planar robot and only **need** that data. \n",
    "\n",
    "However lets take a step back and think a bit. \n",
    "\n",
    "How are we getting wheel odometry ? What is it calculating inside the robot ? We know the encoders work by calculating the amount turns of the wheel, which means its internally using the velocity → distance → x,y positions. \n",
    "\n",
    "Which means that we will be feeding duplicate information to the filter, this is bad, thus it’s recommended to just give the velocities. \n",
    "\n",
    "```yaml\n",
    "#[x_pos   , y_pos    , z_pos,\n",
    "# roll    , pitch    , yaw,\n",
    "# x_vel   , y_vel    , z_vel,\n",
    "# roll_vel, pitch_vel, yaw_vel,\n",
    "# x_accel , y_accel  , z_accel] \n",
    " \n",
    "odom0_config: [false,  false,  false,\n",
    "               false, false, true,\n",
    "               true, false, false,\n",
    "               false, false, true,\n",
    "               false, false, false]\n",
    "imu0_config: [false,  false,  false,\n",
    "               false, false, true,\n",
    "               false, false, false,\n",
    "               false, false, true,\n",
    "               true, false, false]\n",
    "```\n",
    "\n",
    "Now you may have noticed that y_vel is set to false, and this makes sense because since the robot is a differential drive robot it can’t go in the y, this would be different if it were a mecanum robot but it isn’t. \n",
    "\n",
    "You might be tempted to do this as well but its actually better to give y_vel, this is because then it will report as 0 which means that the robot **cannot** not in that direction. \n",
    "\n",
    "```yaml\n",
    "#[x_pos   , y_pos    , z_pos,\n",
    "# roll    , pitch    , yaw,\n",
    "# x_vel   , y_vel    , z_vel,\n",
    "# roll_vel, pitch_vel, yaw_vel,\n",
    "# x_accel , y_accel  , z_accel] \n",
    " \n",
    "odom0_config: [false,  false,  false,\n",
    "               false, false, true,\n",
    "               true, true, false,\n",
    "               false, false, true,\n",
    "               false, false, false]\n",
    "imu0_config: [false,  false,  false,\n",
    "               false, false, true,\n",
    "               false, false, false,\n",
    "               false, false, true,\n",
    "               true, false, false]\n",
    "```\n",
    "\n",
    "However we keep the y_accel as false because often the IMU **will** report a non 0 value which is very bad because then it will cause rapid drift due to noisy y value being sent into the filter. \n",
    "\n",
    "### **Specify your covariance matrices**\n",
    "\n",
    "There are two covariance matrices to specify. The process noise (measurement noise) and initial estimate covariance matrices.\n",
    "\n",
    "Normally this has to be tuned for greater accuracy but we will not go over this part as it is in most cases it’s a game of trail and error unless you have access to the values from the datasheet of the manufacturer. \n",
    "\n",
    "```yaml\n",
    "# [ADVANCED] The process noise covariance matrix can be difficult to tune, and can vary for each application, so it is exposed as a configuration parameter. This matrix represents the noise we add to the total error after each prediction step. \n",
    "\n",
    "# The better the omnidirectional motion model matches your system, the smaller these values can be. However, if users find that a given variable is slow to converge, one approach is to increase the process_noise_covariance diagonal value for the variable in question, which will cause the filter's predicted error to be larger, which will cause the filter to trust the incoming measurement more during correction. \n",
    "\n",
    "# The values are ordered as x, y, z, roll, pitch, yaw, vx, vy, vz, vroll, vpitch, vyaw, ax, ay, az. \n",
    "# Defaults to the matrix below if unspecified.\n",
    "\n",
    "process_noise_covariance: [0.05, 0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                           0,    0.05, 0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                           0,    0,    0.06, 0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                           0,    0,    0,    0.03, 0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                           0,    0,    0,    0,    0.03, 0,    0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                           0,    0,    0,    0,    0,    0.06, 0,     0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                           0,    0,    0,    0,    0,    0,    0.025, 0,     0,    0,    0,    0,    0,    0,    0,\n",
    "                           0,    0,    0,    0,    0,    0,    0,     0.025, 0,    0,    0,    0,    0,    0,    0,\n",
    "                           0,    0,    0,    0,    0,    0,    0,     0,     0.04, 0,    0,    0,    0,    0,    0,\n",
    "                           0,    0,    0,    0,    0,    0,    0,     0,     0,    0.01, 0,    0,    0,    0,    0,\n",
    "                           0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0.01, 0,    0,    0,    0,\n",
    "                           0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0.02, 0,    0,    0,\n",
    "                           0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0.01, 0,    0,\n",
    "                           0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0.01, 0,\n",
    "                           0,    0,    0,    0,    0,    0,    0,     0,     0,    0,    0,    0,    0,    0,    0.015]\n",
    "\n",
    "# [ADVANCED] This represents the initial value for the state estimate error covariance matrix. Setting a diagonal value (variance) to a large value will result in rapid convergence for initial measurements of the variable in question. Users should take care not to use large values for variables that will not be measured directly. \n",
    "\n",
    "# The values are ordered as x, y, z, roll, pitch, yaw, vx, vy, vz, vroll, vpitch, vyaw, ax, ay, az.\n",
    "# Defaults to the matrix below if unspecified.\n",
    "\n",
    "initial_estimate_covariance: [1e-9, 0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                              0,    1e-9, 0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                              0,    0,    1e-9, 0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                              0,    0,    0,    1e-9, 0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                              0,    0,    0,    0,    1e-9, 0,    0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                              0,    0,    0,    0,    0,    1e-9, 0,    0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                              0,    0,    0,    0,    0,    0,    1e-9, 0,    0,    0,     0,     0,     0,    0,    0,\n",
    "                              0,    0,    0,    0,    0,    0,    0,    1e-9, 0,    0,     0,     0,     0,    0,    0,\n",
    "                              0,    0,    0,    0,    0,    0,    0,    0,    1e-9, 0,     0,     0,     0,    0,    0,\n",
    "                              0,    0,    0,    0,    0,    0,    0,    0,    0,    1e-9,  0,     0,     0,    0,    0,\n",
    "                              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     1e-9,  0,     0,    0,    0,\n",
    "                              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     1e-9,  0,    0,    0,\n",
    "                              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     1e-9, 0,    0,\n",
    "                              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    1e-9, 0,\n",
    "                              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,     0,     0,     0,    0,    1e-9]\n",
    "```\n",
    "\n",
    "### 2D Mode\n",
    "\n",
    "Now you might have guessed that since we are a planar robot we really don't need to calculate the `z` axis. Since we don't want to calculate things we don't need we will set the filter to 2d mode.\n",
    "\n",
    "```\n",
    "two_d_mode: true\n",
    "\n",
    "```\n",
    "\n",
    "Everything put together !\n",
    "-------------------------\n",
    "\n",
    "Great job so far ! Now just need to combine what we learned into one file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    ekf.yaml\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekf_filter_node:\n",
    "    ros__parameters:\n",
    "\n",
    "        map_frame: map              # Defaults to \"map\" if unspecified\n",
    "        odom_frame: odom            # Defaults to \"odom\" if unspecified\n",
    "        base_link_frame: base_link  # Defaults to \"base_link\" if unspecified\n",
    "        world_frame: odom           # Defaults to the value of odom_frame if unspecified\n",
    "\n",
    "        # Wheel odometry\n",
    "        odom0: /odom\n",
    "        # IMU\n",
    "        imu0: /imu_plugin/out\n",
    "\n",
    "        #[x_pos   , y_pos    , z_pos,\n",
    "        # roll    , pitch    , yaw,\n",
    "        # x_vel   , y_vel    , z_vel,\n",
    "        # roll_vel, pitch_vel, yaw_vel,\n",
    "        # x_accel , y_accel  , z_accel]\n",
    "\n",
    "        odom0_config: [false,  false,  false,\n",
    "                      false, false, true,\n",
    "                      true, true, false,\n",
    "                      false, false, true,\n",
    "                      false, false, false]\n",
    "        imu0_config: [false,  false,  false,\n",
    "                      false, false, true,\n",
    "                      false, false, false,\n",
    "                      false, false, true,\n",
    "                      true, false, false]\n",
    "\n",
    "        two_d_mode: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our package is complete lets now do a quick test. \n",
    "\n",
    "Build and run your package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "\n",
    "# Build the package\n",
    "colcon build --packages-select botbox_ekf\n",
    "\n",
    "# Source and run\n",
    "source install/setup.bash\n",
    "ros2 launch botbox_ekf ekf.launch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our ekf node is running lets open a new terminal and check if our new topic is avalible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 topic list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/ros2_topic_list.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that we have our two odom topics lets run our detective again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "source install/setup.bash\n",
    "ros2 launch detective detective.launch.py odom_topics:=\"['odom', '/odometry/filtered']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now if you start moving around you should find out that the filtered odom is working much better than the wheel odom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s move around and then see our compare our position with the ground truth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 run  teleop_twist_keyboard teleop_twist_keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/detective_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 class=\"text-center\">\n",
    "        <span class=\"text-primary\">IRL</span>\n",
    "        &nbsp;\n",
    "        <span class=\"\">Run it in real life !</span>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I'm at home right now and don't have access to my lab so were going to connect to BotBox over there in Spain which they have setup for teaching. \n",
    "\n",
    "![](images/IMG_3996.webp)\n",
    "\n",
    "![](images/Screenshot_2024-06-24_at_11.04.33_am.png)\n",
    "\n",
    "I've configured this rosject to connect to this real life environment that I've managed to get access for this robotics developers day but you can get your own from the constructs website [here](https://app.theconstruct.ai/product/standard-boxbot-warehouse-lab/).\n",
    "\n",
    "![](images/botbox_package.png)\n",
    "\n",
    "\n",
    "To be able to connect to the Tortoisebot or your own BotBox from any rosject, including this one, open the rosject and click on the Connect to your robots icon on the bottom right menu bar:\n",
    "\n",
    "<img src=\"images/connect_tortoisebot.png\" width=\"400\"/>\n",
    "\n",
    "1. Click Connect and wait for connection to be established.\n",
    "2. Make sure the robot driver is running inside the robot.\n",
    "3. Check for topics being offered by robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 topic list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can see the topics being published lets test on the real robot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now through testing for the real life robot we have found that its best to go with this configuration. So it is needed to rebuild the package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    ekf.yaml\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekf_filter_node:\n",
    "    ros__parameters:\n",
    "\n",
    "        map_frame: map             \n",
    "        odom_frame: odom           \n",
    "        base_link_frame: base_link \n",
    "        world_frame: odom          \n",
    "\n",
    "        # Wheel odometry\n",
    "        odom0: /odom\n",
    "        # IMU\n",
    "        imu0: /imu\n",
    "\n",
    "        #[x_pos   , y_pos    , z_pos,\n",
    "        # roll    , pitch    , yaw,\n",
    "        # x_vel   , y_vel    , z_vel,\n",
    "        # roll_vel, pitch_vel, yaw_vel,\n",
    "        # x_accel , y_accel  , z_accel]\n",
    "\n",
    "        odom0_config: [true,  true,  false,\n",
    "                      false, false, true,\n",
    "                      false, false, false,\n",
    "                      false, false, false,\n",
    "                      false, false, false]\n",
    "\n",
    "        imu0_config: [false,  false,  false,\n",
    "                      false, false, true,\n",
    "                      false, false, false,\n",
    "                      false, false, true,\n",
    "                      true, false, false]\n",
    "\n",
    "        two_d_mode: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "\n",
    "# Build the package\n",
    "colcon build --packages-select botbox_ekf\n",
    "\n",
    "# Source and run\n",
    "source install/setup.bash\n",
    "ros2 launch botbox_ekf ekf.launch.py use_sim_time:=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets launch our detective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "source install/setup.bash\n",
    "ros2 launch detective detective.launch.py odom_topics:=\"['odom', '/odometry/filtered']\" real_life:=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would really help us to see what we are doing in rviz considering we don't have ground truth to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rviz2 -d ~/ros2_ws/src/rviz/test_odom.rviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets move around and see how our topics compare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 run teleop_twist_keyboard teleop_twist_keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/real_life_test_rviz.gif)\n",
    "![](images/real_life_test_camera.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Launch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start sim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/sim_ws\n",
    "source install/setup.bash\n",
    "ros2 launch tortoisebot_gazebo gazebo.launch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "efk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "source install/setup.bash\n",
    "ros2 launch botbox_ekf ekf.launch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "source install/setup.bash\n",
    "ros2 launch detective detective.launch.py odom_topics:=\"['odom', 'odometry/filtered']\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rviz2 -d ~/ros2_ws/src/rviz/test_odom.rviz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
